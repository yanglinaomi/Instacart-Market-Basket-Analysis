{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and load train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "\n",
    "from numpy import arange\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('../data/train_data.csv')\n",
    "test_data=pd.read_csv('../data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['reordered']=train_data['reordered'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reordered</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reorder_last5_count</th>\n",
       "      <td>0.386591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_last5_count</th>\n",
       "      <td>0.386080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reorder_rate_last5</th>\n",
       "      <td>0.297105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_prd_reorder_ratio</th>\n",
       "      <td>0.281601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_prd_count</th>\n",
       "      <td>0.248376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prd_reordered_ratio</th>\n",
       "      <td>0.167360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prd_avg_cart_postion</th>\n",
       "      <td>0.129354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prd_count</th>\n",
       "      <td>0.126969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aisle_count</th>\n",
       "      <td>0.103531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept_count</th>\n",
       "      <td>0.095437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_orders_count</th>\n",
       "      <td>0.092544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_prd_first</th>\n",
       "      <td>0.077346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_day_since_order</th>\n",
       "      <td>0.060470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_user_prd_since_1st</th>\n",
       "      <td>0.058832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prd_cart_order</th>\n",
       "      <td>0.050944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_avg_prd</th>\n",
       "      <td>0.049082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_reorder_ratio</th>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          reordered\n",
       "reordered                  1.000000\n",
       "reorder_last5_count        0.386591\n",
       "order_last5_count          0.386080\n",
       "reorder_rate_last5         0.297105\n",
       "user_prd_reorder_ratio     0.281601\n",
       "user_prd_count             0.248376\n",
       "prd_reordered_ratio        0.167360\n",
       "prd_avg_cart_postion       0.129354\n",
       "prd_count                  0.126969\n",
       "aisle_count                0.103531\n",
       "dept_count                 0.095437\n",
       "user_orders_count          0.092544\n",
       "user_prd_first             0.077346\n",
       "mean_day_since_order       0.060470\n",
       "order_user_prd_since_1st   0.058832\n",
       "prd_cart_order             0.050944\n",
       "user_avg_prd               0.049082\n",
       "user_reorder_ratio         0.007100\n",
       "product_id                 0.002786\n",
       "user_id                    0.000429"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(train_data.corr()[['reordered']]).sort_values(by='reordered', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we predict whether user makes repeat purchase for the products, we split train_data to train and val datasets by user to make sure same users in train or val dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correlation rate for user_reordered_ratio is quite low, so we decide to drop it.\n",
    "X = train_data.drop(['product_id', 'user_reorder_ratio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users = list(train_data.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize users\n",
    "random.shuffle(total_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split with test_size=0.25\n",
    "train_users = total_users[:98406]\n",
    "test_users  = total_users[98406:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.set_index('user_id').loc[train_users,:]\n",
    "X_val  = X.set_index('user_id').loc[test_users,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train.reordered\n",
    "y_val = X_val.reordered\n",
    "X_train = X_train.drop(['reordered'],axis=1)\n",
    "X_val = X_val.drop(['reordered'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test for prediction.\n",
    "X_test=test_data.drop(['order_id','user_id', 'product_id', 'user_reorder_ratio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = train_data.drop(['product_id', 'user_reorder_ratio', 'user_id', 'reordered'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = train_data['reordered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9022\n",
       "1    0.0978\n",
       "Name: reordered, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline f1 score is calculated referring to \n",
    "[this website](https://stats.stackexchange.com/questions/390200/what-is-the-baseline-of-the-f1-score-for-a-binary-classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our assumption is that predict all as positive, which is 'reordered =1' for our case. \n",
    "According to y_train_full data, the probabilities p(reordered=1)= 0.0978. \n",
    "\n",
    "If we assume that predicts all as positive:                                                                             \n",
    "precision = (true positive)/(total predict positive) = 0.0978                                                           \n",
    "recall = (true positive)/(total actual positive) = 1                                                                     \n",
    "So our baseline f1 score is:                                                                                            \n",
    "f1 score=(2 x precision x recall)/(precision+recall) = (2x 0.0978)/(1+0.0978) = **0.178**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric and models chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, f1 score is used as evaluation metric. F1 score is the harmonic mean of precision and recall. It weights these two equally and is normally use for imbalanced dataset, especially for the case where we have more negative examples that positive examples [[3]](https://stats.stackexchange.com/questions/329102/comparing-f1-score-across-imbalanced-data-sets). In this project, we have imbalanced dataset with positive (reordered =1) and negative (reordered=0) ratio as 9:1 roughly.\n",
    "\n",
    "This is binary classfication problem for this project. So we choose some models to deal with binary classification issue, i.e. logisitic regression (basic binary classification model), XGBoost/Lightgbm (Gradient Tree Boosting techniques), Random Forest (Bagging Based techniques).\n",
    "\n",
    "XGBoost/Lightgbm performs well on imbalanced classification datasets. It offers a way to tune the training algorithm to pay more attention to misclassification of the minority class for datasets with a skewed class distribution[[4]](https://machinelearningmastery.com/xgboost-for-imbalanced-classification/).\n",
    "\n",
    "RF is robust to overfitting. Parameterization for random forest remains quite intuitive and straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for modelling and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those classification problems that have a severe class imbalance, the default threshold (0.5) can result in poor performance. As such, a simple and straightforward approach to improving the performance of a classifier that predicts probabilities on an imbalanced classification problem is to tune the threshold used to map probabilities to class labels.\n",
    "\n",
    "We use the following functions to get optimal threshold. refers to [this website](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_threshold(yhat):\n",
    "    # keep probabilities for the positive outcome only\n",
    "    probs = yhat[:, 1]\n",
    "    # define thresholds\n",
    "    thresholds = arange(0, 1, 0.01)\n",
    "    # evaluate each threshold\n",
    "    scores = [f1_score(y_val, to_labels(probs, t)) for t in thresholds]\n",
    "    # get best threshold\n",
    "    ix = argmax(scores)\n",
    "    return thresholds[ix], scores[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print f1 score for train and val dataset\n",
    "def train_val_f1_score(threshold, model):\n",
    "    y_pred_train=[1 if pred[1]>=threshold else 0 for pred in model.predict_proba(X_train)]\n",
    "    y_pred_val=[1 if pred[1]>=threshold else 0 for pred in model.predict_proba(X_val)]\n",
    "    train_f1score=f1_score(y_train,y_pred_train)\n",
    "    val_f1score=f1_score(y_val,y_pred_val)\n",
    "    print('f1-score on train data: {}'.format(train_f1score))\n",
    "    print('f1-score on validate data: {}'.format(val_f1score))\n",
    "    return train_f1score, val_f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are applied to create the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model, ot):\n",
    "    predictions = model.predict_proba(X_test)\n",
    "    test_data['reordered']=predictions[:, 1]\n",
    "    final = test_data[['order_id','product_id','reordered']]\n",
    "    dic=create_product_list(final, ot)\n",
    "    dic_join=join_products(dic)\n",
    "    submission=pd.DataFrame.from_dict(dic_join, orient='index').reset_index()\n",
    "    submission.columns=['order_id', 'products']\n",
    "    submission['order_id']=submission['order_id'].astype('int')\n",
    "    test_data.drop('reordered', axis=1, inplace=True)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_product_list(df, threshold):\n",
    "    dic={}\n",
    "    for index, row in df.iterrows():\n",
    "        if row.reordered>=threshold:\n",
    "            dic.setdefault(row.order_id, []).append(int(row.product_id))\n",
    "\n",
    "    for order in df.order_id:\n",
    "        if order not in dic:\n",
    "            dic[order] = 'None'\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_products(dic):\n",
    "    for key, value in dic.items():\n",
    "        dic[key]= \" \".join(str(item) for item in value)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Results DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Classifier', 'Hyperparams','Optimal Threshold', \n",
    "                                'Train f1 score', 'Val f1 score',\n",
    "                                'Test f1 score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('logreg', LogisticRegression(max_iter=200))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_params = {\n",
    "    'logreg__C': [0.1, 0.5, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe_lr = GridSearchCV(pipe_lr, pipe_lr_params, cv=2, verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(max_iter=200))]),\n",
       "             n_jobs=-1, param_grid={'logreg__C': [0.1, 0.5, 1]}, verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_bestmodel = grid_pipe_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('logreg', LogisticRegression(C=0.1, max_iter=200))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_bestmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the optimal threshold and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val_lr_pipe = pipe_lr_bestmodel.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_lr, f1_lr = optimal_threshold(preds_val_lr_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.42871514208120814)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_lr,f1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train data: 0.42673495214306245\n",
      "f1-score on validate data: 0.42871514208120814\n"
     ]
    }
   ],
   "source": [
    "# print f1 score for train and val data with optimal threshold\n",
    "lr_train_f1, lr_val_f1 = train_val_f1_score(ot_lr, pipe_lr_bestmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction and kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with whole train dataset before prediction\n",
    "pred_model = pipe_lr_bestmodel.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission dataframe\n",
    "submission_df = submission(pred_model, ot_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save kaggle submission file as .csv file\n",
    "submission_df.to_csv('../submission/submission_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle score: 0.36261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(\n",
    "    {'Classifier': 'Logistic Regression', \n",
    "     'Hyperparams': grid_pipe_lr.best_params_,\n",
    "     'Optimal Threshold': ot_lr,\n",
    "     'Train f1 score': round(lr_train_f1, 3), \n",
    "     'Val f1 score': round(lr_val_f1, 3),\n",
    "    'Test f1 score': round(0.36261, 3)},\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = xgb.XGBClassifier(objective='binary:logistic', eval_metric='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_params = {'max_depth':[3,5,6],\n",
    "               'n_estimators':[500,1000,1200],\n",
    "               'learning_rate':[0.02, 0.05, 0.1]          \n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgbc = GridSearchCV(xgbc, xgbc_params, cv=2, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, eval_metric='error',\n",
       "                                     gamma=None, gpu_id=None,\n",
       "                                     importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.02, 0.05, 0.1],\n",
       "                         'max_depth': [3, 5, 6],\n",
       "                         'n_estimators': [500, 1000, 1200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_best_model = grid_xgbc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02, 'max_depth': 6, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgbc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the optimal threshold and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val_xgbc = xgbc_best_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_xgbc, f1_xgbc= optimal_threshold(preds_val_xgbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21, 0.43291098317645454)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_xgbc, f1_xgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train data: 0.4338459620100586\n",
      "f1-score on validate data: 0.43291098317645454\n"
     ]
    }
   ],
   "source": [
    "# with optimal threshold\n",
    "xgbc_train_f1, xgbc_val_f1 = train_val_f1_score(ot_xgbc, xgbc_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction and kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "pred_model = xgbc_best_model.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_submission = submission(pred_model, ot_xgbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_submission.to_csv('../submission/submission_xgbc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle score: 0.36466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(\n",
    "    {'Classifier': 'XGBoost', \n",
    "     'Hyperparams': grid_xgbc.best_params_, \n",
    "     'Optimal Threshold': ot_xgbc,\n",
    "     'Train f1 score': round(xgbc_train_f1, 3), \n",
    "     'Val f1 score': round(xgbc_val_f1, 3),\n",
    "    'Test f1 score': round(0.36466, 3)},\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm=lgb.LGBMClassifier(objective='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'max_depth':[3, 5,8],\n",
    "               'learning_rate':[0.02, 0.05, 0.1],\n",
    "               'num_iterations':[500,1000],             \n",
    "              } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgbm = GridSearchCV(lgbm, lgbm_params, cv=2, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=LGBMClassifier(objective='binary'), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.02, 0.05, 0.1],\n",
       "                         'max_depth': [3, 5, 8],\n",
       "                         'num_iterations': [500, 1000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lgbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'num_iterations': 500}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best_model=grid_lgbm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the optimal threshold and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val_lgbm=lgbm_best_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_lgbm, f1_lgbm=optimal_threshold(preds_val_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22, 0.4321678381917166)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_lgbm, f1_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train data: 0.4309935974294663\n",
      "f1-score on validate data: 0.4321678381917166\n"
     ]
    }
   ],
   "source": [
    "lgbm_train_f1, lgbm_val_f1 = train_val_f1_score(ot_lgbm, lgbm_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction and kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "pred_lgbm_model = lgbm_best_model.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on full train data: 0.4313568423517632\n"
     ]
    }
   ],
   "source": [
    "y_pred_fulltrain=[1 if pred[1]>=ot_lgbm else 0 for pred in pred_lgbm_model.predict_proba(X_train_full)]\n",
    "print('f1-score on full train data: {}'.format(f1_score(y_train_full,y_pred_fulltrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_submission = submission(pred_lgbm_model, ot_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_submission.to_csv('../submission/submission_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle score: 0.36479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(\n",
    "    {'Classifier': 'Lightgbm', \n",
    "     'Hyperparams': grid_lgbm.best_params_, \n",
    "     'Optimal Threshold': ot_lgbm,\n",
    "     'Train f1 score': round(lgbm_train_f1, 3), \n",
    "     'Val f1 score': round(lgbm_val_f1, 3),\n",
    "    'Test f1 score': round(0.36479, 3)},\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {'max_depth':[15,12,10,8,5],\n",
    "               'n_estimators':[100,250,500,750,1000],               \n",
    "              } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc = GridSearchCV(rfc, rfc_params, cv=2, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [15, 12, 10, 8, 5],\n",
       "                         'n_estimators': [100, 250, 500, 750, 1000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_best_model=grid_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the optimal threshold and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val_rfc=rfc_best_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_rfc, f1_rfc=optimal_threshold(preds_val_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21, 0.4313631102748657)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_rfc, f1_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train data: 0.4365175780744583\n",
      "f1-score on validate data: 0.4313631102748657\n"
     ]
    }
   ],
   "source": [
    "rfc_train_f1, rfc_val_f1 = train_val_f1_score(ot_rfc, rfc_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction and kaggle submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc_model = rfc_best_model.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on full train data: 0.4353991178651163\n"
     ]
    }
   ],
   "source": [
    "y_pred_fulltrain=[1 if pred[1]>=ot_rfc else 0 for pred in pred_rfc_model.predict_proba(X_train_full)]\n",
    "print('f1-score on full train data: {}'.format(f1_score(y_train_full,y_pred_fulltrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_submission = submission(pred_rfc_model, ot_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_submission.to_csv('../submission/submission_rfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle score: 0.36755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(\n",
    "    {'Classifier': 'Random Forest', \n",
    "     'Hyperparams': grid_rfc.best_params_,\n",
    "     'Optimal Threshold': ot_rfc,\n",
    "     'Train f1 score': round(rfc_train_f1, 3), \n",
    "     'Val f1 score': round(rfc_val_f1, 3),\n",
    "    'Test f1 score': round(0.36755, 3)},\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier          | Hyperparams                                                                                                                                   | Optimal Threshold |   Train f1 score |   Val f1 score |   Test f1 score |\n",
    "|:--------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|:----------------|--------------:|---------------:|---------------:|\n",
    "| Logistic Regression | {'logreg__C': 0.1}                                                           |            0.20 |          0.427 |           0.429  |0.363|\n",
    "| XGBoost            | {'learning_rate': 0.02, 'max_depth': 6, 'n_estimators': 1000}                     |            0.21 |          0.434 |           0.433 |0.365|\n",
    "| Lightgbm                 | {'learning_rate': 0.1, 'max_depth': 3, 'num_iterations': 500}                    |            0.22  |          0.431 |           0.432 |0.365|\n",
    "| Random Forest       | {'max_depth': 12, 'n_estimators': 1000} |            0.21 |          0.437 |           0.431 |0.368|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the performance on the test data versus the performance on the training data, we do oberve some overfitting. \n",
    "\n",
    "We can observe that amongst these models, random forest performances best. However, due to large dataset, it requests quite long time to train random forest model. The second best performance models are boost models, i.e. XGBoost and Lightgbm. They requires shorter time to train, especially Lightgbm model needs even shorter time than XGBoost. Not surprisely, the third best performance model is Logistic Regression due to its naive nature.\n",
    "\n",
    "The perfromance gap betweem Random Forest & Logistic Regression is not that much. If we would like to obtain rough result quickly, we can apply logistic regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Best Model Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importance')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sorted_idx = rfc_best_model.feature_importances_.argsort()\n",
    "plt.barh(X_train.columns[sorted_idx], rfc_best_model.feature_importances_[sorted_idx])\n",
    "plt.xlabel('F score', size=12)\n",
    "plt.title('Feature Importance', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last5 orders and user_product related features are the strongest features. If customer bought products frequently during lastest orders, he/she would have a preference for these products during that period of time and may tend to buy again in next purchase. User_prodcuts features indicates customers' long term perference of some products. For example, customer may prefer certain brands or may prefer certain type of products, i.e. organic food. Thus, customer will also tend to purchase these products repeatedly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we believe that our model can predict product reorder in next purchase effectively, with f1 score as 0.368. The prediction result can help increase sales and imrpove customer retention rate for Instacart. We suggest Instacart to utilize of data science to understand customers' short term and long term preference. For example, through customer latest orders, we can understand customers' recent preference. We also can understand customers' long term preference through more historical order data. \n",
    "\n",
    "As mentioned in previous section, customer retention rate is important to Instacart. \n",
    "With prediction results from our model, we can provide the following recommendations to improve customer retention rate. \n",
    "1. Offer personalized discounts and credits on products that customers may purchase repeatedly in their next orders.\n",
    "2. Send engaging emails to customers based on the prediction result for repeating purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://en.wikipedia.org/wiki/Instacart\n",
    "2. https://www.lightspeedhq.com/blog/customer-retention-rate/\n",
    "3. https://stats.stackexchange.com/questions/329102/comparing-f1-score-across-imbalanced-data-sets\n",
    "4. https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
    "5. https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "6. https://stats.stackexchange.com/questions/390200/what-is-the-baseline-of-the-f1-score-for-a-binary-classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": "3",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "108.667px",
    "left": "56px",
    "top": "164.667px",
    "width": "255.99px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
